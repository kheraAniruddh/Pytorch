{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "yBkpOKkH8lqN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "imTIh3w48iNv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import tqdm\n",
        "import pandas as pd\n",
        "import PIL.Image as Image\n",
        "print(torch.__version__)\n",
        "!python --version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JWv9RoF28t58",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lKRsBdvr81Ha",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir .kaggle\n",
        "\n",
        "api_token = {\"username\":\"aniruddhk123\",\"key\":\"GET YOUR OWN KEY\"}\n",
        "import json\n",
        "import zipfile\n",
        "import os\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "    \n",
        "!chmod 600 /content/.kaggle/kaggle.json\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v data\n",
        "!kaggle competitions download -c nyu-cv-fall-2018\n",
        "os.chdir('data/competitions/nyu-cv-fall-2018')\n",
        "for file in os.listdir():\n",
        "    zip_ref = zipfile.ZipFile(file, 'r')\n",
        "    zip_ref.extractall()\n",
        "    zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qp2ycJ3I8_Yo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "####---------------data.py##################\n",
        "from __future__ import print_function\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# once the images are loaded, how do we pre-process them before being passed into the network\n",
        "# by default, we resize the images to 32 x 32 in size\n",
        "# and normalize them to mean = 0 and standard-deviation = 1 based on statistics collected from\n",
        "# the training set\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomAffine(degrees=40,translate=(.3,.3),scale=(.8,1.2)),\n",
        "    transforms.ColorJitter(brightness=.8),\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.3337, 0.3064, 0.3171), ( 0.2672, 0.2564, 0.2629))])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.3337, 0.3064, 0.3171), ( 0.2672, 0.2564, 0.2629))])\n",
        "\n",
        "\n",
        "def initialize_data(folder):\n",
        "    train_zip = folder + '/train_images.zip'\n",
        "    test_zip = folder + '/test_images.zip'\n",
        "    if not os.path.exists(train_zip) or not os.path.exists(test_zip):\n",
        "        raise(RuntimeError(\"Could not find \" + train_zip + \" and \" + test_zip\n",
        "              + ', please download them from https://www.kaggle.com/c/nyu-cv-fall-2017/data '))\n",
        "    # extract train_data.zip to train_data\n",
        "    train_folder = folder + '/train_images'\n",
        "    if not os.path.isdir(train_folder):\n",
        "        print(train_folder + ' not found, extracting ' + train_zip)\n",
        "        zip_ref = zipfile.ZipFile(train_zip, 'r')\n",
        "        zip_ref.extractall(folder)\n",
        "        zip_ref.close()\n",
        "    # extract test_data.zip to test_data\n",
        "    test_folder = folder + '/test_images'\n",
        "    if not os.path.isdir(test_folder):\n",
        "        print(test_folder + ' not found, extracting ' + test_zip)\n",
        "        zip_ref = zipfile.ZipFile(test_zip, 'r')\n",
        "        zip_ref.extractall(folder)\n",
        "        zip_ref.close()\n",
        "\n",
        "    # make validation_data by using images 00000*, 00001* and 00002* in each class\n",
        "    val_folder = folder + '/val_images'\n",
        "    if not os.path.isdir(val_folder):\n",
        "        print(val_folder + ' not found, making a validation set')\n",
        "        os.mkdir(val_folder)\n",
        "        for dirs in os.listdir(train_folder):\n",
        "            if dirs.startswith('000'):\n",
        "                os.mkdir(val_folder + '/' + dirs)\n",
        "                for f in os.listdir(train_folder + '/' + dirs):\n",
        "                    if f.startswith('00000') or f.startswith('00001') or f.startswith('00002'):\n",
        "                        # move file to validation folder\n",
        "                        os.rename(train_folder + '/' + dirs + '/' + f, val_folder + '/' + dirs + '/' + f)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "29nL92vP9ysY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########--------------main.py PART-1----------------###########\n",
        "!kaggle config set -n path -v data\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "torch.manual_seed(1)\n",
        "torch.cuda.manual_seed(1)\n",
        "\n",
        "### Data Initialization and Loading\n",
        "data_path = '.'\n",
        "initialize_data(data_path) # extracts the zip files, makes a validation set\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KFkSeOvffj27",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### ------------------Data Augmentation-----------##\n",
        "\n",
        "def load_pickled_data(file, columns):\n",
        "        with open(file, mode='rb') as f:\n",
        "            dataset = pickle.load(f)\n",
        "        return tuple(map(lambda c: dataset[c], columns))\n",
        "\n",
        "\n",
        "def pickle_data(x, y, save_loc):\n",
        "    print(\"Saving pickle at \" + save_loc)\n",
        "    save = {\"features\": x, \"labels\": y}\n",
        "\n",
        "    with open(save_loc, \"wb\") as f:\n",
        "        pickle.dump(save, f)\n",
        "\n",
        "\n",
        "def pickle_data_from_folder(data_folder, save_loc):\n",
        "    if not os.path.isdir(data_folder):\n",
        "        print(\"Data folder must be a folder and should contains sub folders for each label\")\n",
        "        return\n",
        "\n",
        "    resize_transform = transforms.Resize((32, 32))\n",
        "    sub_folders = os.listdir(data_folder)\n",
        "\n",
        "    count = 0\n",
        "    for sub_folder in sub_folders:\n",
        "        sub_folder = os.path.join(data_folder, sub_folder)\n",
        "\n",
        "        if not os.path.isdir(sub_folder):\n",
        "            continue\n",
        "        label = int(sub_folder.split(\"/\")[-1])\n",
        "\n",
        "        for image in os.listdir(sub_folder):\n",
        "            count += 1\n",
        "\n",
        "    save = {\"features\": np.empty([count, IMG_SIZE, IMG_SIZE, 3], dtype=np.uint8),\n",
        "            \"labels\": np.empty([count], dtype=int)}\n",
        "    i = 0\n",
        "    for sub_folder in sub_folders:\n",
        "        sub_folder = os.path.join(data_folder, sub_folder)\n",
        "\n",
        "        if not os.path.isdir(sub_folder):\n",
        "            continue\n",
        "        label = int(sub_folder.split(\"/\")[-1])\n",
        "        for image in os.listdir(sub_folder):\n",
        "            image = os.path.join(sub_folder, image)\n",
        "            pic = Image.open(image)\n",
        "            pic = resize_transform(pic)\n",
        "            pic = np.array(pic)\n",
        "            save[\"features\"][i] = pic\n",
        "            save[\"labels\"][i] = label\n",
        "            i += 1\n",
        "\n",
        "    with open(save_loc, \"wb\") as f:\n",
        "        pickle.dump(save, f)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_pickle_path = \"aug_data/train.p\"\n",
        "pickle_data_from_folder(\"data\"+\"train_images\", train_pickle_path)\n",
        "print(\"Saved train.p from original data folder\")\n",
        "print(\"Now extending data\")\n",
        "x, y = load_pickled_data(train_pickle_path, [\"features\", \"labels\"])\n",
        "extender = Extender(x, y, 1, .75)\n",
        "x_extended, y_extended = extender.flip()\n",
        "print(\"Data extension complete\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jb53NMNifiSr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from skimage.transform import rotate, warp, ProjectiveTransform\n",
        "from torchvision import datasets, transforms\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "\n",
        "class Extender:\n",
        "    def __init__(self, data_images, data_labels, ratio=0.5, intensity=0.75):\n",
        "        self.x = data_images\n",
        "        self.y = data_labels\n",
        "        self.intensity = intensity\n",
        "        self.ratio = ratio\n",
        "        \n",
        "        # horizontally flipped\n",
        "        self.horizontally_flippable_classes = [11, 12, 13, 15, 17, 18, \n",
        "                                               22, 26, 30, 35]\n",
        "        \n",
        "        # vertically flipped\n",
        "        self.vertically_flippable_classes = np.array([1, 5, 12, 15, 17])\n",
        "        \n",
        "        # flipped both vertically and horizontally\n",
        "        self.both_flippable = [32, 40]\n",
        "        \n",
        "        # Tcontains pair which first can be generated by \n",
        "        # horizontally flipping the other.\n",
        "        self.flip_exchangeable = np.array([\n",
        "            (19, 20),\n",
        "            (20, 19),\n",
        "            (33, 34),\n",
        "            (34, 33),\n",
        "            (36, 37),\n",
        "            (37, 36),\n",
        "            (38, 39),\n",
        "            (39, 38)\n",
        "        ])\n",
        "    \n",
        "    def extend_and_balance(self, custom_counts=None):\n",
        "        print(\"Extending and balancing dataset with intesity\", self.intensity)\n",
        "        x, y = self.flip()\n",
        "        _, class_counts = np.unique(y, return_counts=True)\n",
        "        max_count = max(class_counts)\n",
        "        \n",
        "        if custom_counts is None:\n",
        "            total = max_count * NUM_CLASSES\n",
        "        else:\n",
        "            total = np.sum(custom_counts)\n",
        "        \n",
        "        x_balanced = np.empty([0, x.shape[1], x.shape[2],x.shape[3]],\n",
        "                              dtype=np.float32)\n",
        "        y_balanced = np.empty([0], dtype=y.dtype)\n",
        "        \n",
        "        for c, class_count in zip(range(NUM_CLASSES), tqdm(class_counts)):\n",
        "            x_org = (x[y == c] / 255.).astype(np.float32)\n",
        "            y_org = y[y == c]\n",
        "            \n",
        "            x_balanced = np.append(x_balanced, x_org, axis=0)\n",
        "            \n",
        "            max_count = max_count if custom_counts is None else custom_counts[c]\n",
        "            for i in range(max_count // class_count):\n",
        "                x_mod = self.rotate(x_org)\n",
        "                x_mod = self.projection_transform(x_mod)\n",
        "                x_balanced = np.append(x_balanced, x_mod, axis=0)\n",
        "            \n",
        "            if max_count % class_count > 0:\n",
        "                x_mod = self.rotate(x_org[:(max_count % class_count)])\n",
        "                x_mod = self.projection_transform(x_mod)\n",
        "            \n",
        "                x_balanced = np.append(x_balanced, x_mod, axis=0)\n",
        "            \n",
        "            extension = np.full(x_balanced.shape[0] - y_balanced.shape[0],\n",
        "                                c, dtype=y_balanced.dtype)\n",
        "            y_balanced = np.append(y_balanced, extension)\n",
        "            \n",
        "            del x_org\n",
        "            del y_org\n",
        "        \n",
        "        return (x_balanced * 255).astype(np.uint8), y_balanced\n",
        "    \n",
        "    def flip(self):\n",
        "        x = np.empty([0, self.x.shape[1], self.x.shape[2], \n",
        "                      self.x.shape[3]], \n",
        "                      dtype=self.x.dtype)\n",
        "        y = np.empty([0], dtype=self.y.dtype)\n",
        "        \n",
        "        for c in range(NUM_CLASSES):\n",
        "            # Add existing data\n",
        "            x = np.append(x, self.x[self.y == c], axis=0)\n",
        "            \n",
        "            if c in self.horizontally_flippable_classes:\n",
        "                # Flip columns and append\n",
        "                x = np.append(x, self.x[self.y == c][:, :, ::-1, :], \n",
        "                              axis=0)\n",
        "                \n",
        "            if c in self.vertically_flippable_classes:\n",
        "                # Flip rows and append\n",
        "                x = np.append(x, self.x[self.y == c][:, ::-1, :, :],\n",
        "                              axis=0)\n",
        "            \n",
        "            if c in self.flip_exchangeable[:, 0]:\n",
        "                flip_c = self.flip_exchangeable[self.flip_exchangeable[:, 0] == c]\n",
        "                flip_c = flip_c[0][1]\n",
        "                \n",
        "                # Flip other class horizontally \n",
        "                x = np.append(x, self.x[self.y == flip_c][:, :, ::-1, :], \n",
        "                              axis=0)\n",
        "            \n",
        "            if c in self.both_flippable:\n",
        "                # Flip both rows and columns\n",
        "                x = np.append(x, self.x[self.y == c][:, ::-1, ::-1, :],\n",
        "                             axis=0)\n",
        "            \n",
        "            # Extend y now\n",
        "            y = np.append(y, np.full(x.shape[0] - y.shape[0], c, \n",
        "                                     dtype=int))\n",
        "        \n",
        "        return (x, y)\n",
        "    \n",
        "    def rotate(self, x):\n",
        "        indices = np.random.choice(x.shape[0], int(x.shape[0] * self.ratio),\n",
        "                                   replace=False)\n",
        "        \n",
        "        # If we rotate more than 30 degrees, context is lost.\n",
        "        change = 30. * self.intensity\n",
        "        x_return = np.empty(x.shape, dtype=x.dtype)\n",
        "        for i in indices:\n",
        "            x_return[i] = rotate(x[i], random.uniform(-change, change), mode=\"edge\")\n",
        "        \n",
        "        return x_return\n",
        "    \n",
        "    def projection_transform(self, x):\n",
        "        image_size = x.shape[1]\n",
        "        \n",
        "        change = image_size * 0.3 * self.intensity\n",
        "        \n",
        "        x_return = np.empty(x.shape, dtype=x.dtype)\n",
        "        \n",
        "        indices = np.random.choice(x.shape[0], int(x.shape[0] * self.ratio),\n",
        "                                   replace=False)\n",
        "        for i in indices:\n",
        "            changes = []\n",
        "            for _ in range(8):\n",
        "                changes.append(random.uniform(-change, change))\n",
        "            \n",
        "            transform = ProjectiveTransform()\n",
        "            transform.estimate(np.array(\n",
        "                (\n",
        "                    (changes[0], changes[1]), # top left\n",
        "                    (changes[2], image_size - changes[3]), # bottom left\n",
        "                    (image_size - changes[4], changes[5]), # top right\n",
        "                    (image_size - changes[6], image_size - changes[7]) # bottom right\n",
        "                )), np.array(\n",
        "                (\n",
        "                    (0, 0),\n",
        "                    (0, image_size),\n",
        "                    (image_size, 0),\n",
        "                    (image_size, image_size)\n",
        "                ))\n",
        "            )\n",
        "            \n",
        "            x_return[i] = warp(x[i], transform, output_shape=(image_size, image_size),\n",
        "                        order=1, mode=\"edge\")\n",
        "        \n",
        "        return x_return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-E6zQf4pK-YU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.ImageFolder(data_path + '/train_images',\n",
        "                         transform=train_transforms),\n",
        "    batch_size=256, shuffle=True, num_workers=1)\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    datasets.ImageFolder(data_path + '/val_images',\n",
        "                         transform=val_transforms),\n",
        "    batch_size=256, shuffle=False, num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vooSUJldWfSs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "############------------model.py--------------############\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "nclasses = 43 # GTSRB as 43 classes\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 3, kernel_size=1)\n",
        "        self.conv2 = nn.Conv2d(3, 32, kernel_size=3,  padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        \n",
        "        self.conv6 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv7 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        \n",
        "      \n",
        "        self.fc1 = nn.Linear(229376, 1024)\n",
        "        self.fc2 = nn.Linear(1024, nclasses)\n",
        "\n",
        "        \n",
        "    def flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "      \n",
        "      \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(F.max_pool2d(x,3,stride=1,padding=1))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        layer1 = x\n",
        "        \n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = F.relu(F.max_pool2d(x,3,stride=1,padding=1)) \n",
        "        x = F.dropout(x, training=self.training)\n",
        "        layer2 = x\n",
        "        \n",
        "        x = self.conv6(x)\n",
        "        x = self.conv7(x)\n",
        "        x = F.relu(F.max_pool2d(x,3,stride=1,padding=1)) \n",
        "        x = F.dropout(x, training=self.training)\n",
        "        layer3 = x\n",
        "        \n",
        "        flat_layer1 = layer1.view(-1, self.flat_features(layer1))\n",
        "        flat_layer2 = layer2.view(-1, self.flat_features(layer2))\n",
        "        flat_layer3 = layer3.view(-1, self.flat_features(layer3))\n",
        "#         print( self.flat_features(layer1)+ self.flat_features(layer2)+ self.flat_features(layer3))\n",
        "        x = torch.cat([flat_layer1, flat_layer2, flat_layer3],1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1ck6m4tSeqk-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=Net()\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v6J6W_n0EzNy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "model = Net()\n",
        "\n",
        "state_dict = torch.load('data/competitions/nyu-cv-fall-2018/resnet_100.pth')\n",
        "model.load_state_dict(state_dict)  \n",
        "model.cuda()\n",
        "optimizer = optim.SGD(model.parameters(), lr=.001, momentum=.7)\n",
        "  \n",
        "DEVICE = 'cuda' \n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    correct=0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "    with open('train_acc.csv', 'a') as f:\n",
        "        f.write(\"{},{}\\n\".format(round(100.*correct.numpy()/len(train_loader.dataset),2),epoch))\n",
        "        \n",
        "    \n",
        "    \n",
        "def validation():\n",
        "    model.eval()\n",
        "    validation_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in val_loader:\n",
        "      with torch.no_grad():\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        output = model(data)\n",
        "        validation_loss += F.nll_loss(output, target, size_average=False).item() # sum up batch loss\n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    validation_loss /= len(val_loader.dataset)\n",
        "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        validation_loss, correct, len(val_loader.dataset),\n",
        "        100. * correct / len(val_loader.dataset)))\n",
        "    with open('val_acc.csv', 'a') as f:\n",
        "        f.write(\"{},{}\\n\".format(round(100.*correct.numpy()/len(val_loader.dataset),2),epoch))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qcNUV49vFABP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(101, 201):\n",
        "    train(epoch)\n",
        "    validation()\n",
        "    model_file = 'resnet_' + str(epoch) + '.pth'\n",
        "    torch.save(model.state_dict(), model_file)\n",
        "    print('\\nSaved model to ' + model_file + '. You can run `python evaluate.py ' + model_file + '` to generate the Kaggle formatted csv file')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nxidov-FMB1Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wetorch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HwUm28TwEdaQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from skimage.transform import rotate, warp, ProjectiveTransform\n",
        "import random\n",
        "\n",
        "class Extender:\n",
        "    def __init__(self, data_images, data_labels, ratio=0.5, intensity=0.75):\n",
        "        self.x = data_images\n",
        "        self.y = data_labels\n",
        "        self.intensity = intensity\n",
        "        self.ratio = ratio\n",
        "        \n",
        "        # horizontally flipped for new images\n",
        "       \n",
        "        self.horizontally_flippable_classes = [11, 12, 13, 15, 17, 18, \n",
        "                                               22, 26, 30, 35]\n",
        "        \n",
        "        # vertically flipped for new images\n",
        "        self.vertically_flippable_classes = np.array([1, 5, 12, 15, 17])\n",
        "        \n",
        "        # flipped both vertically and horizontally to get same image\n",
        "        self.both_flippable = [32, 40]\n",
        "        \n",
        "        # These ones contains pair which first can be generated by \n",
        "        self.flip_exchangeable = np.array([\n",
        "            (19, 20),\n",
        "            (20, 19),\n",
        "            (33, 34),\n",
        "            (34, 33),\n",
        "            (36, 37),\n",
        "            (37, 36),\n",
        "            (38, 39),\n",
        "            (39, 38)\n",
        "        ])\n",
        "    \n",
        "    def extend_and_balance(self, custom_counts=None):\n",
        "        print(\"Extending and balancing dataset with intesity\", self.intensity)\n",
        "        x, y = self.flip()\n",
        "        _, class_counts = np.unique(y, return_counts=True)\n",
        "        max_count = max(class_counts)\n",
        "        \n",
        "        if custom_counts is None:\n",
        "            total = max_count * 43\n",
        "        else:\n",
        "            total = np.sum(custom_counts)\n",
        "        \n",
        "        x_balanced = np.empty([0, x.shape[1], x.shape[2], x.shape[3]],\n",
        "                              dtype=np.float32)\n",
        "        y_balanced = np.empty([0], dtype=y.dtype)\n",
        "        \n",
        "        for c, class_count in zip(range(NUM_CLASSES), tqdm(class_counts)):\n",
        "            x_org = (x[y == c] / 255.).astype(np.float32)\n",
        "            y_org = y[y == c]\n",
        "            \n",
        "            x_balanced = np.append(x_balanced, x_org, axis=0)\n",
        "            \n",
        "            max_count = max_count if custom_counts is None else custom_counts[c]\n",
        "            for i in range(max_count // class_count):\n",
        "                x_mod = self.rotate(x_org)\n",
        "                x_mod = self.projection_transform(x_mod)\n",
        "                x_balanced = np.append(x_balanced, x_mod, axis=0)\n",
        "            \n",
        "            if max_count % class_count > 0:\n",
        "                x_mod = self.rotate(x_org[:(max_count % class_count)])\n",
        "                x_mod = self.projection_transform(x_mod)\n",
        "            \n",
        "                x_balanced = np.append(x_balanced, x_mod, axis=0)\n",
        "            \n",
        "            extension = np.full(x_balanced.shape[0] - y_balanced.shape[0],\n",
        "                                c, dtype=y_balanced.dtype)\n",
        "            y_balanced = np.append(y_balanced, extension)\n",
        "            \n",
        "            del x_org\n",
        "            del y_org\n",
        "        \n",
        "        return (x_balanced * 255).astype(np.uint8), y_balanced\n",
        "    \n",
        "    def flip(self):\n",
        "        x = np.empty([0, self.x.shape[1], self.x.shape[2], \n",
        "                      self.x.shape[3]], \n",
        "                      dtype=self.x.dtype)\n",
        "        y = np.empty([0], dtype=self.y.dtype)\n",
        "        \n",
        "        for c in range(43):\n",
        "            # Add existing data\n",
        "            x = np.append(x, self.x[self.y == c], axis=0)\n",
        "            \n",
        "            if c in self.horizontally_flippable_classes:\n",
        "                # Flip columns and append\n",
        "                x = np.append(x, self.x[self.y == c][:, :, ::-1, :], \n",
        "                              axis=0)\n",
        "                \n",
        "            if c in self.vertically_flippable_classes:\n",
        "                # Flip rows and append\n",
        "                x = np.append(x, self.x[self.y == c][:, ::-1, :, :],\n",
        "                              axis=0)\n",
        "            \n",
        "            if c in self.flip_exchangeable[:, 0]:\n",
        "                flip_c = self.flip_exchangeable[self.flip_exchangeable[:, 0] == c]\n",
        "                flip_c = flip_c[0][1]\n",
        "                \n",
        "                # Flip other class horizontally \n",
        "                x = np.append(x, self.x[self.y == flip_c][:, :, ::-1, :], \n",
        "                              axis=0)\n",
        "            \n",
        "            if c in self.both_flippable:\n",
        "                # Flip both rows and columns\n",
        "                x = np.append(x, self.x[self.y == c][:, ::-1, ::-1, :],\n",
        "                             axis=0)\n",
        "            \n",
        "            # Extend y now\n",
        "            y = np.append(y, np.full(x.shape[0] - y.shape[0], c, \n",
        "                                     dtype=int))\n",
        "        \n",
        "        return (x, y)\n",
        "    \n",
        "    def rotate(self, x):\n",
        "        indices = np.random.choice(x.shape[0], int(x.shape[0] * self.ratio),\n",
        "                                   replace=False)\n",
        "        \n",
        "        # If we rotate more than 30 degrees, context is lost.\n",
        "        change = 30. * self.intensity\n",
        "        x_return = np.empty(x.shape, dtype=x.dtype)\n",
        "        for i in indices:\n",
        "            x_return[i] = rotate(x[i], random.uniform(-change, change), mode=\"edge\")\n",
        "        \n",
        "        return x_return\n",
        "    \n",
        "    def projection_transform(self, x):\n",
        "        image_size = x.shape[1]\n",
        "        \n",
        "        change = image_size * 0.3 * self.intensity\n",
        "        \n",
        "        x_return = np.empty(x.shape, dtype=x.dtype)\n",
        "        \n",
        "        indices = np.random.choice(x.shape[0], int(x.shape[0] * self.ratio),\n",
        "                                   replace=False)\n",
        "        for i in indices:\n",
        "            changes = []\n",
        "            for _ in range(8):\n",
        "                changes.append(random.uniform(-change, change))\n",
        "            \n",
        "            transform = ProjectiveTransform()\n",
        "            transform.estimate(np.array(\n",
        "                (\n",
        "                    (changes[0], changes[1]), # top left\n",
        "                    (changes[2], image_size - changes[3]), # bottom left\n",
        "                    (image_size - changes[4], changes[5]), # top right\n",
        "                    (image_size - changes[6], image_size - changes[7]) # bottom right\n",
        "                )), np.array(\n",
        "                (\n",
        "                    (0, 0),\n",
        "                    (0, image_size),\n",
        "                    (image_size, 0),\n",
        "                    (image_size, image_size)\n",
        "                ))\n",
        "            )\n",
        "            \n",
        "            x_return[i] = warp(x[i], transform, output_shape=(image_size, image_size),\n",
        "                        order=1, mode=\"edge\")\n",
        "        \n",
        "        return x_return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ilJJ8-b9lGgL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HVO6scXB_Gxb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
